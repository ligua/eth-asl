\documentclass[11pt]{article}
\usepackage[a4paper, portrait, margin=1in]{geometry}
\usepackage{mathtools}
\usepackage{listings}
\usepackage[dvipsnames]{xcolor}
\usepackage{color}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[colorlinks=true,urlcolor=blue,linkcolor=black]{hyperref}

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}

\fancypagestyle{firstpagefooter}
{
\lfoot{Compiled: \today}
\cfoot{}
\rfoot{\thepage}
}
\cfoot{\thepage}


\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}


\newcommand{\code}[1]{\lstinline[language=Java]{#1}}
\newcommand{\get}[0]{\texttt{GET}}
\newcommand{\set}[0]{\texttt{SET}}
\newcommand{\todo}[1]{\fcolorbox{black}{Apricot}{TODO: #1}}
\newcommand{\linkmain}[1]{\href{https://gitlab.inf.ethz.ch/pungast/asl-fall16-project/blob/master/src/main/java/asl/#1.java}{#1}}
\newcommand{\linktest}[1]{\href{https://gitlab.inf.ethz.ch/pungast/asl-fall16-project/blob/master/src/test/java/asl/#1.java}{#1}}

\newcommand{\resultsurl}[1]{\href{https://gitlab.inf.ethz.ch/pungast/asl-fall16-project/blob/master/results/#1}{gitlab.inf.ethz.ch/.../results/#1}}


\begin{document}

\title{Advanced Systems Lab (Fall'16) -- Third Milestone}

\author{Name: \emph{Taivo Pungas}\\Legi number: \emph{15-928-336}}

\date{
\vspace{4cm}
\textbf{Grading} \\
\begin{tabular}{|c|c|}
\hline  \textbf{Section} & \textbf{Points} \\ 
\hline  1 &  \\ 
\hline  2 &  \\ 
\hline  3 &  \\ 
\hline  4 &  \\ 
\hline  5 &  \\ 
\hline \hline Total & \\
\hline 
\end{tabular} 
}

\maketitle
\thispagestyle{firstpagefooter}
\newpage

\tableofcontents

\clearpage
% --------------------------------------------------------------------------------
% --------------------------------------------------------------------------------
\section{System as One Unit}\label{sec:part1-system-one-unit}
% --------------------------------------------------------------------------------
% --------------------------------------------------------------------------------

\subsection{Data}

The experimental data used in this section comes from the updated trace experiment, found in \texttt{\href{https://gitlab.inf.ethz.ch/pungast/asl-fall16-project/tree/master/results/trace\_rep3}{results/trace\_rep3}} (short names \texttt{trace\_ms*}, \texttt{trace\_mw} and \texttt{trace\_req} in Milestone~1). For details, see Milestone~2, Appendix A.

The first 2 minutes and last 2 minutes were dropped as warm-up and cool-down time similarly to previous milestones.

\subsection{Model}
\label{sec:part1:model}

In this section I create an M/M/1 model of the system. This means the following definitions and assumptions:
\begin{itemize}
	\item The queues are defined as having infinite buffer capacity.
	\item The population size is infinite.
	\item The service discipline is FCFS.
	\item Interarrival times and the service times are exponentially distributed.
	\item We treat the SUT as a single server and as a black box.
	\item Arrivals are individual, so we have a birth-death process.
\end{itemize}
 
\paragraph{Parameter estimation}
Using the available experimental data, it is not possible to directly calculate the mean arrival rate $\lambda$ and mean service rate $\mu$ so we need to estimate them somehow. I estimated both using throughput of the system: I take $\lambda$ to be the \emph{mean} throughput over 1-second windows, and $\mu$ to be the the \emph{maximum} throughput in any 1-second window, calculated from middleware logs. I chose a 1-second window because a too small window is highly susceptible to noise whereas a too large window size drowns out useful information.

\paragraph{Problems}
The assumptions above obviously do not hold for our actual system. Especially strong is the assumption of a single server; since we actually have multiple servers, this model is likely to predict the behaviour of the system very poorly. A second problem arises from my very indirect method of estimating parameters for the model (and an arbitrary choice of time window) which introduces inaccuracies.

\subsection{Comparison of model and experiments}

Explain the characteristics and behavior of the model built, and compare it with the experimental data (collected both outside and inside the middleware). Map the similarities and differences to aspects of the design or the experiments.

Table~\ref{tbl:part1:comparison_table} shows a comparison of the predictions of the M/M/1 model with actual results from the trace experiment. 

\todo{this whole subsection}

\todo{mention that IRTL doesn't hold for the model}

\input{../results/analysis/part1_mm1/comparison_table.txt}

\begin{figure}[h]
\includegraphics[width=\textwidth]{../results/analysis/part1_mm1/graphs/response_time_quantiles_actual_and_predicted.pdf}
\caption{Quantiles of the response time distribution: experimental results and predictions of the M/M/1 model. Note the extreme difference in the response time scale.}
\label{fig:part1:quantiles_responsetime}
\end{figure}

\todo{mention} that number of jobs is calculated using Little's law

\begin{figure}[h]
\includegraphics[width=\textwidth]{../results/analysis/part1_mm1/graphs/queue_time_quantiles_actual_and_predicted.pdf}
\caption{Quantiles of the waiting time distribution: experimental results and predictions of the M/M/1 model. Note the extreme difference in the queue time scale.}
\label{fig:part1:quantiles_queuetime}
\end{figure}


\clearpage
% --------------------------------------------------------------------------------
% --------------------------------------------------------------------------------
\section{Analysis of System Based on Scalability Data}\label{sec:part2-analysis-scalability}
% --------------------------------------------------------------------------------
% --------------------------------------------------------------------------------

\subsection{Data}

The experimental data used in this section comes from Milestone~2 Section~1 and can be found in \texttt{\href{https://gitlab.inf.ethz.ch/pungast/asl-fall16-project/tree/master/results/throughput}{results/throughput}}.


\subsection{Model}

The assumptions and definitions of the M/M/m model are the same as for the M/M/1 model laid out in Section~\ref{sec:part1:model} with the following modifications:

\begin{itemize}
	\item We treat the SUT as a collection of $m$ servers.
	\item All jobs waiting for service are held in one queue.
	\item If any server is idle, an arriving job is serviced immediately.
	\item If all servers are busy, an arriving job is added to the queue.
\end{itemize}

\paragraph{Parameters}
\todo{} describe how I found the parameters


\paragraph{Problems}
\todo{}

\begin{enumerate}
	\item I actually have $m$ queues (one for each server), not a single queue; each request is assigned to a server when \linkmain{LoadBalancer} receives it.
	\item I map requests to servers uniformly. M/M/m assumes that each server takes a request when it finishes with the previous one, but that is not true in my case -- I take earlier
\end{enumerate}

\subsection{Comparison of model and experiments}

\todo{}

\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth]{../results/analysis/part2_mmm/graphs/traffic_intensity_vs_clients.pdf}
\caption{\todo{}}
\label{fig:part2:trafficintensity}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{../results/analysis/part2_mmm/graphs/response_time_predicted_and_actual.pdf}
\caption{\todo{} note difference in scale}
\label{fig:part2:responsetime}
\end{figure}

\input{../results/analysis/part2_mmm/comparison_table.txt}


\clearpage
% --------------------------------------------------------------------------------
% --------------------------------------------------------------------------------
\section{System as Network of Queues}\label{sec:part3-network-of-queues}
% --------------------------------------------------------------------------------
% --------------------------------------------------------------------------------

\subsection{Guidelines}
Length: 1-3 pages

Based on the outcome of the different modeling efforts from the previous sections, build a comprehensive network of queues model for the whole system. Compare it with experimental data and use the methods discussed in the lecture and the book to provide an in-depth analysis of the behavior. This includes the identification and analysis of bottlenecks in your system. Make sure to follow the model-related guidelines described in the Notes!


\clearpage
% --------------------------------------------------------------------------------
% --------------------------------------------------------------------------------
\section{Factorial Experiment}\label{sec:part4-2k-experiment}
% --------------------------------------------------------------------------------
% --------------------------------------------------------------------------------

\subsection{Guidelines}
Length: 1-3 pages

Design a $2^k$ factorial experiment and follow the best practices outlined in the book and in the lecture to analyze the results. You are free to choose the parameters for the experiment and in case you have already collected data in the second milestone that can be used as source for this experiment, you can reuse it. Otherwise, in case you need to run new experiments anyway, we recommend exploring the impact of request size on the middleware together with an other parameter.

\clearpage
% --------------------------------------------------------------------------------
% --------------------------------------------------------------------------------
\section{Interactive Law Verification}\label{sec:part5-interactive-law}
% --------------------------------------------------------------------------------
% --------------------------------------------------------------------------------

\subsection{Data}

The experimental data used in this section comes from Milestone~2, Section~2 (Effect of Replication) and can be found in \texttt{\href{https://gitlab.inf.ethz.ch/pungast/asl-fall16-project/tree/master/results/replication}{results/replication}} (short name \texttt{replication-S*-R*-r*} in Milestone~2). This includes a total of 27 experiments in 9 different configurations.

The first 2 minutes and last 2 minutes were \textbf{not} dropped because the Interactive Response Time Law (IRTL) should hold also in warm-up and cool-down periods. Repetitions at the same configuration were considered as separate experiments.

\subsection{Model}

We are assuming a closed system, i.e. clients wait for a response from the server before sending another request. Under this assumption, the IRTL should hold:

$$R = \frac{N}{X} - Z$$

where $R$ is mean response time, $Z$ is waiting time in the client, $N$ is the number of clients and $X$ is throughput.

\subsection{Results}

Using IRTL, we can verify the validity of experiments by calculating the predicted throughput $X_{predicted}$ (given the number of clients $C$ and mean response time $R$) and comparing it with actual throughput $X_{actual}$. This is precisely what I did for all experiments of Milestone~2, Section~2. $C=180$ in all experiments, and both $R$ and $X_{actual}$ are aggregated results reported by the three memaslap instances generating load in that experiment.

\begin{figure}[h]
\centering
\begin{subfigure}[t]{0.49\textwidth}
\includegraphics[width=\textwidth]{../results/analysis/part5_irtl/graphs/error_percentage.pdf}
\caption{Histogram of the relative error of throughput predicted using IRTL, counting the number of experiments in a given error range. Note the horizontal scale does not include 0.}
\label{fig:part5:error_percentage}
\end{subfigure}
\begin{subfigure}[t]{0.49\textwidth}
\includegraphics[width=\textwidth]{../results/analysis/part5_irtl/graphs/predicted_vs_actual_throughput.pdf}
\caption{Throughput predicted using IRTL (dark points), as a function of actual throughput calculated from experimental data. The red line shows hypothetical perfect predictions (the $x=y$ line). Note the horizontal scale does not include 0.}
\label{fig:part5:predicted_vs_actual}
\end{subfigure}
\caption{Evaluation of the validity of Milestone~2 Section~2 experiments}
\end{figure}

If we assume the wait time $Z$ to be 0, we get a mean relative prediction error of $-1.01\%$, defined as $\frac{X_{predicted}-X_{actual}}{X_{actual}}$. The distribution of these errors is shown in Figure~\ref{fig:part5:error_percentage}; the distribution looks reasonably symmetric. Figure~\ref{fig:part5:predicted_vs_actual} plots $X_{predicted}$ against $X_{actual}$ and shows again that the predicted throughput is very close to actual throughput, but consistently smaller in all regions of the graph.

If we assume a nonzero $Z$ and estimate it from the experiments, we get a mean estimated wait time of -0.111ms. Clearly this is impossible: wait time must be non-negative.

To explain these results, we need to answer the question: why is the actual throughput lower than the actual throughput? It could be that memaslap starts the clock for a new request before stopping the clock for the previous request -- which would violate the closed system assumption -- but this is very unlikely as it would be a major design flaw in memaslap.

A more plausible hypothesis is that the effective value of $N$ is slightly lower than the concurrency I set using the relevant command line flags -- because the number of cores in the memaslap machine is much lower than the concurrency I'm using.

Regardless of the exact reason of the deviation, the IRTL holds to a reasonably high accuracy. Perfect accuracy is impossible even without the middleware: in the baseline experiments (Milestone~1 Section~2), relative prediction error is 0.2\%-0.5\% in a selection of values of $N$ that I checked.

\todo{if time} think about what could be causing the -1\%, but not a priority


% potential reasons from slides: network effects, processing overhead, exceptions and non-normal return values



% --------------------------------------------------------------------------------
% --------------------------------------------------------------------------------
% --------------------------------- Appendices -----------------------------------
% --------------------------------------------------------------------------------
% --------------------------------------------------------------------------------

\clearpage

\section*{Appendix A: Template appendix}
\label{sec:appa}
\addcontentsline{toc}{section}{Appendix A: Template appendix}

\end{document}