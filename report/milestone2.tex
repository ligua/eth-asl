\documentclass[11pt]{article}
\usepackage[a4paper, portrait, margin=1in]{geometry}
\usepackage{mathtools}
\usepackage{listings}
\usepackage[dvipsnames]{xcolor}
\usepackage{color}
\usepackage{graphicx}
\usepackage[colorlinks=true,urlcolor=blue,linkcolor=gray]{hyperref}


\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}

\newcommand{\code}[1]{\lstinline[language=Java]{#1}}
\newcommand{\todo}[1]{\fcolorbox{black}{Apricot}{TODO: #1}}
\newcommand{\linkmain}[1]{\href{https://gitlab.inf.ethz.ch/pungast/asl-fall16-project/blob/master/src/main/java/asl/#1.java}{#1}}
\newcommand{\linktest}[1]{\href{https://gitlab.inf.ethz.ch/pungast/asl-fall16-project/blob/master/src/test/java/asl/#1.java}{#1}}

\newcommand{\resultsurl}[1]{\href{https://gitlab.inf.ethz.ch/pungast/asl-fall16-project/blob/master/results/#1}{gitlab.inf.ethz.ch/.../results/#1}}




\begin{document}

\title{Advanced Systems Lab (Fall'16) -- Second
Milestone}

\author{Name: \emph{Taivo Pungas}\\Legi number: \emph{15-928-336}}

\date{
\vspace{4cm}
\textbf{Grading} \\
\begin{tabular}{|c|c|}
\hline  \textbf{Section} & \textbf{Points} \\ 
\hline  1 &  \\ 
\hline  2 &  \\ 
\hline  3 &  \\ 
\hline \hline Total & \\
\hline 
\end{tabular} 
}

\maketitle

\newpage

\section*{Notes on writing the report \small{(remove this page for submission)}}

Before starting to work on this milestone please remember:
\begin{itemize}
\item The prerequisite to a successful completion to this milestone is to have a stable system and also the necessary logging functionalities in place. 
\item Depending on the workload and goal of the experiment, you might need to change the sampling rate from the default level. Make sure to indicate when doing so.
\item The choice of experiment length and repetitions is up to you to decide, please make sure that you do not include warm-up and cool-down phases in the measurements. There are many experiments to run in this milestone, try to make a tradeoff.  
\item We recommend that you have scripts in place to deploy and run experiments.
\item All experiments have to be executed on the Microsoft Azure cloud.
\item When plotting graphs include errors or measures of accuracy whenever possible. 
\item Keep the report compact and concise! The total length should not exceed 20 pages. Log listings are not counted in this length, but all text, figures and tables are. If you have many logs, compress them by experiment and reference the archive instead of the independent files.
\end{itemize}

In this milestone we expect to see the different experiments you ran to exercise the system, and with each experiment we expect a clear description of the system configuration used, the hypothesis on behavior and the explanation of the behavior observed (in terms of the different design decisions taken beforehand) -- \emph{missing either of these for an experiment might make you lose all points for that given experiment!} 

Keep in mind that for a good explanation of the results of an experiment you might have to use one or more methods of data analysis presented in the lecture and in the book. You might have to combine measurements taken in the middleware with the ones at the clients to be able to provide a full picture.

Please feel free to structure the three sections of this report as it makes most sense for your experiments and explanations, but please respect the goal of each section. Also, similarly to the first milestone, include tables and descriptions about your experimental setup before each set of experiments.

\medskip

\pagebreak

% --------------------------------------------------------------------------------
% --------------------------------------------------------------------------------
\section{Maximum Throughput}
% --------------------------------------------------------------------------------
% --------------------------------------------------------------------------------

Find the highest throughput of your system for 5 servers with no replication and a read-only workload configuration. What is the minimum number of threads and clients (rounded to multiple of 10) that together achieve this throughput? Explain why the system reaches its maximum throughput at these points and show how the performance changes around these configurations. Provide a detailed breakdown of the time spent in the middleware for each operation type.

\subsection{Experimental question}

The system under test (SUT), in this section and hereafter, is the middleware together with the memcached servers running on virtual machines in the Azure cloud.

In this section, I will run experiments to find out a) the maximum throughput of the SUT, b) the number of read threads ($T$) in the middleware that achieves this c) the number of virtual clients ($C$) that achieves this.

To this end, I will measure throughput (the number of requests the SUT successfully responds to, per unit of time) as a function of $T$ and $C$. I will find the maximum sustained throughput of the SUT, i.e. the throughput with which the response time does not increase rapidly with additional clients.

\subsection{Hypothesis}

I predict the following.

\paragraph{Number of threads} Throughput will be maximised at a very low value of $T=1$, after which the throughput will start to decrease rapidly.

The reason for that lies in my implementation: since each thread runs through an infinite while-loop even if there are no requests to process, the threads almost never wait or sleep and use 100\% of the resources allocated to them by the scheduler. For this reason, once $T$ is high enough that not all threads can run concurrently, threads need to wait to be allocated time, and this waiting decreases throughput significantly. The total number of threads used by the system is given as $S * (T + 1) + 1$; for $S=5$ and $T=1$, the system uses 11 threads. This is more than what's available in a Basic A4 machine, so increasing $T$ will only decrease throughput.

Note that the middleware can be easily changed to change this non-optimal behaviour by making the threads sleep for a short period if there is nothing to do.

\paragraph{Number of clients} Throughput will be maximised at \todo{x} virtual clients. Let's assume that $T=1$. Since there are 5 servers with no replication, we can estimate the total throughput for GET requests as 5 times the throughput of a single read thread: $tp=5 \cdot tp_1$ (this assumes that requests spend negligible time in LoadBalancer).

\begin{itemize}
\item Draw graphs with expected results
\item Even try to predict variance and statistical properties
\item Make bullet points with explanations
\item Use „modeling“ to make hypothesis
\item Formulate a number of questions on what you expect to see, develop a hypothesis around the behavior that is expected, explain the hypothesis, and write it all down
\end{itemize}

\subsection{Experiments}
\begin{center}
\small{
\smallskip
\begin{tabular}{|c|c|}
\hline Number of servers & 5 \\ 
\hline Number of client machines & 3 \\ 
\hline Virtual clients / machine & \todo{} \\ 
\hline Workload & Key 16B, Value 128B, Writes 0\% \todo{} \\
\hline Middleware: replication factor & 1 \\ 
\hline Middleware: read threads & \todo{} \\ 
\hline Runtime x repetitions & 60s x 5 \todo{} \\ 
\hline Log files & \todo{} \\
\hline 
\end{tabular} }
\end{center}

\subsection{Results}
Reporting experiment results. Comparison of hypothesis and experiment results.

% --------------------------------------------------------------------------------
% --------------------------------------------------------------------------------
\section{Effect of Replication}
% --------------------------------------------------------------------------------
% --------------------------------------------------------------------------------

Explore how the behavior of your system changes for a 5\%-write workload with S=3,5 and 7 server backends and the following three replication factors:
\begin{itemize} 
\item Write to $1$ (no replication) 
\item Write to $\ceil{\frac{S}{2}}$ (half) 
\item Write to all 
\end{itemize}

Answer at least the following questions: Are \texttt{get} and \texttt{set} requests impacted the same way by different setups? If yes/no, why? Which operations become more expensive inside the middleware as the configuration changes? How does the scalability of your system compare to that of an ideal implementation? Provide the graphs and tables necessary to support your claims.


\subsection{Experimental question}
\begin{itemize}
\item Define the „system(s) under test“
\item Define what to measure and understand why
\end{itemize}

\subsection{Hypothesis}
\begin{itemize}
\item Draw graphs with expected results
\item Even try to predict variance and statistical properties
\item Make bullet points with explanations
\item Use „modeling“ to make hypothesis
\item Formulate a number of questions on what you expect to see, develop a hypothesis around the behavior that is expected, explain the hypothesis, and write it all down
\end{itemize}

\subsection{Experiments}
\begin{center}
\small{
\smallskip
\begin{tabular}{|c|c|}
\hline Number of servers & $\in \{3, 5, 7\}$ \\ 
\hline Number of client machines & 3 \\ 
\hline Virtual clients / machine & \todo{} \\ 
\hline Workload & Key 16B, Value 128B, Writes 5\% \todo{} \\
\hline Middleware: replication factor & $\in \{1, ceil(S/2), S\}$ \\ 
\hline Middleware: read threads & \todo{} \\ 
\hline Runtime x repetitions & 60s x 5 \todo{} \\ 
\hline Log files & \todo{} \\
\hline 
\end{tabular} }
\end{center}

\subsection{Results}
Reporting experiment results. Comparison of hypothesis and experiment results.
 
% --------------------------------------------------------------------------------
% --------------------------------------------------------------------------------
\section{Effect of Writes}
% --------------------------------------------------------------------------------
% --------------------------------------------------------------------------------

In this section, you should study the changes in throughput and response time of your system as the percentage of write operations increases. Use a combination of 3 to 7 servers and vary the number of writes between 1\% and 10\% (e.g. 1\%, 5\% and 10\%). The experiments need to be carried out for the replication factors R=1 and R=all.  

For what number of servers do you see the biggest impact (relative to base case) on performance? Investigate the main reason for the reduced performance and provide a detailed explanation of the behavior of the system. Provide the graphs and tables necessary to support your claims.


\subsection{Experimental question}
\begin{itemize}
\item Define the „system(s) under test“
\item Define what to measure and understand why
\end{itemize}

\subsection{Hypothesis}
\begin{itemize}
\item Draw graphs with expected results
\item Even try to predict variance and statistical properties
\item Make bullet points with explanations
\item Use „modeling“ to make hypothesis
\item Formulate a number of questions on what you expect to see, develop a hypothesis around the behavior that is expected, explain the hypothesis, and write it all down
\end{itemize}

\subsection{Experiments}
\begin{center}
\small{
\smallskip
\begin{tabular}{|c|c|}
\hline Number of servers & $\in \{3, 4, 5, 6, 7\}$ \\ 
\hline Number of client machines & 3 \\ 
\hline Virtual clients / machine & \todo{} \\ 
\hline Workload & Key 16B, Value 128B, Writes $\in \{1\%, 5\%, 10\%\}$ \todo{} \\
\hline Middleware: replication factor & $\in \{1, S\}$ \\ 
\hline Middleware: read threads & \todo{} \\ 
\hline Runtime x repetitions & 60s x 5 \todo{} \\ 
\hline Log files & \todo{} \\
\hline 
\end{tabular} }
\end{center}

\subsection{Results}
Reporting experiment results. Comparison of hypothesis and experiment results.


\pagebreak

\section*{Logfile listing}

\begin{tabular}{|c|l|}
\hline \textbf{Short name }& \textbf{Location} \\ 
\hline baseline-m*-c*-r* & \href{https://gitlab.inf.ethz.ch/pungast/asl-fall16-project/blob/master/results/baseline}{gitlab.inf.ethz.ch/.../results/baseline/baseline\_memaslap*\_conc*\_rep*.out} \\ 
\hline trace-ms4 & \resultsurl{trace\_rep3/memaslap4.out} \\ 
\hline 
\end{tabular} 
 
\end{document}